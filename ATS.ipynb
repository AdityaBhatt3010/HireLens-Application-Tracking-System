{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17bd95c-dff9-4963-9bcc-492cc99957ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import docx\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e32c9e-46e8-4217-ac83-258f4af5f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyfiglet import figlet_format\n",
    "from termcolor import colored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c00805-1635-4582-ae90-eb0b2a586f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a32b78-f7de-4ee1-9b9d-101806d07301",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a01e718-3d53-4c2f-97b0-d86b593249a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94b7b27c-e09c-46a0-ae99-cc3ad4a02fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7278b116-f8a5-4cdd-b47e-fd43cfd230b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization\n",
    "    filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "597035da-8222-40b2-993a-68a8e842cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resume(job_description, resume_text):\n",
    "    corpus = [preprocess_text(job_description), preprocess_text(resume_text)]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b165b2-a957-4d1c-96ad-532cee1f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def employer_mode():\n",
    "    job_role = input(\"Enter the Job Role: \")\n",
    "    job_description = input(\"Enter the Job Description: \")\n",
    "    with open(\"job_description.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Role: {job_role}\\n\\n{job_description}\")\n",
    "    print(\"Job description saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686749a-27d7-4fb2-a24a-63a0a882be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_mode():\n",
    "    if not os.path.exists(\"job_description.txt\"):\n",
    "        print(\"No job description found! Please ask the employer to create one first.\")\n",
    "        return\n",
    "\n",
    "    with open(\"job_description.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        job_description = f.read()\n",
    "        resume_path = input(\"Enter File Path: \") \n",
    "    if not os.path.exists(resume_path):\n",
    "        print(\"File not found! Please check the path and try again.\")\n",
    "        return\n",
    "\n",
    "    if resume_path.endswith(\".pdf\"):\n",
    "        resume_text = extract_text_from_pdf(resume_path)\n",
    "    elif resume_path.endswith(\".docx\"):\n",
    "        resume_text = extract_text_from_docx(resume_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format! Please provide a PDF or DOCX file.\")\n",
    "        return\n",
    "\n",
    "    score = rank_resume(job_description, resume_text)\n",
    "    print(f\"Your ATS Score: {score:.2f} (Higher is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd98416-1396-480c-8264-d8e2a0aaa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    a = figlet_format(\"[ Application Tracking System ]\", font=\"slant\", width=900)\n",
    "    print(colored(a, \"green\"))  # Prints the stylish \"ATS\" text in green\n",
    "    print(\"Welcome to AI-powered ATS System!\")\n",
    "    user_type = input(\"Are you an Employer or a Candidate? (E/C): \").strip().lower()\n",
    "\n",
    "    if user_type == \"E\":\n",
    "        employer_mode()\n",
    "    elif user_type == \"C\":\n",
    "        candidate_mode()\n",
    "    else:\n",
    "        print(\"Invalid choice! Please restart and enter 'E' for Employer or 'C' for Candidate.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
